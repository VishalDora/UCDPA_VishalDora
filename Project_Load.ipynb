{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2714346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing files\n",
    "import os as files_upload #paths to file\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import warnings# warning filter\n",
    "\n",
    "# ploting libraries\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "# importing relevant ML libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ML models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# setting default theme\n",
    "sns.set(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=False, rc=None)\n",
    "\n",
    "# warning handling\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e095eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all files under the input directory\n",
    "for dirname, _, filenames in files_upload.walk('/Data'):\n",
    "    for filename in filenames:\n",
    "        print(files_upload.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35db6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for the training set\n",
    "tr_path = \"Data/train_u6lujuX_CVtuZ9i.csv\"\n",
    "#path for the testing set\n",
    "te_path = \"Data/test_Y3wMUE5_7gLdaTN.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv file as a DataFrame\n",
    "tr_df = pd.read_csv(tr_path)\n",
    "# explore the first 5 rows\n",
    "tr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2152a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv file as a DataFrame\n",
    "te_df = pd.read_csv(te_path)\n",
    "# explore the first 5 rows\n",
    "te_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc8da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"training set (row, col): {tr_df.shape}\\n\\ntesting set (row, col): {te_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3cfb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#column information\n",
    "tr_df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf7ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary statistics\n",
    "tr_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the Id column is not needed, let's drop it for both test and train datasets\n",
    "tr_df.drop('Loan_ID',axis=1,inplace=True)\n",
    "te_df.drop('Loan_ID',axis=1,inplace=True)\n",
    "#checking the new shapes\n",
    "print(f\"training set (row, col): {tr_df.shape}\\n\\ntesting set (row, col): {te_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c19575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values in decsending order\n",
    "tr_df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c197fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling the missing data\n",
    "print(\"Before filling missing values\\n\\n\",\"#\"*50,\"\\n\")\n",
    "null_cols = ['Credit_History', 'Self_Employed', 'LoanAmount','Dependents', 'Loan_Amount_Term', 'Gender', 'Married']\n",
    "\n",
    "\n",
    "for col in null_cols:\n",
    "    print(f\"{col}:\\n{tr_df[col].value_counts()}\\n\",\"-\"*50)\n",
    "    tr_df[col] = tr_df[col].fillna(\n",
    "    tr_df[col].dropna().mode().values[0] )   \n",
    "\n",
    "    \n",
    "tr_df.isnull().sum().sort_values(ascending=False)\n",
    "print(\"After filling missing values\\n\\n\",\"#\"*50,\"\\n\")\n",
    "for col in null_cols:\n",
    "    print(f\"\\n{col}:\\n{tr_df[col].value_counts()}\\n\",\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5bcc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all the columns.columns\n",
    "#Cols = tr_df.tolist()\n",
    "#list of all the numeric columns\n",
    "num = tr_df.select_dtypes('number').columns.to_list()\n",
    "#list of all the categoric columns\n",
    "cat = tr_df.select_dtypes('object').columns.to_list()\n",
    "\n",
    "#numeric df\n",
    "loan_num =  tr_df[num]\n",
    "#categoric df\n",
    "loan_cat = tr_df[cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fac77fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr_df[cat[-1]].value_counts())\n",
    "#tr_df[cat[-1]].hist(grid = False)\n",
    "\n",
    "#print(i)\n",
    "total = float(len(tr_df[cat[-1]]))\n",
    "plt.figure(figsize=(8,10))\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.countplot(tr_df[cat[-1]])\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,height + 3,'{:1.2f}'.format(height/total),ha=\"center\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbbfdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in loan_num:\n",
    "    plt.hist(loan_num[i])\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat[:-1]: \n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(2,3,1)\n",
    "    sns.countplot(x=i ,hue='Loan_Status', data=tr_df ,palette='plasma')\n",
    "    plt.xlabel(i, fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical values to numbers\n",
    "\n",
    "to_numeric = {'Male': 1, 'Female': 2,\n",
    "'Yes': 1, 'No': 2,\n",
    "'Graduate': 1, 'Not Graduate': 2,\n",
    "'Urban': 3, 'Semiurban': 2,'Rural': 1,\n",
    "'Y': 1, 'N': 0,\n",
    "'3+': 3}\n",
    "\n",
    "# adding the new numeric values from the to_numeric variable to both datasets\n",
    "tr_df = tr_df.applymap(lambda lable: to_numeric.get(lable) if lable in to_numeric else lable)\n",
    "te_df = te_df.applymap(lambda lable: to_numeric.get(lable) if lable in to_numeric else lable)\n",
    "\n",
    "# convertind the Dependents column\n",
    "Dependents_ = pd.to_numeric(tr_df.Dependents)\n",
    "Dependents__ = pd.to_numeric(te_df.Dependents)\n",
    "\n",
    "# dropping the previous Dependents column\n",
    "tr_df.drop(['Dependents'], axis = 1, inplace = True)\n",
    "te_df.drop(['Dependents'], axis = 1, inplace = True)\n",
    "\n",
    "# concatination of the new Dependents column with both datasets\n",
    "tr_df = pd.concat([tr_df, Dependents_], axis = 1)\n",
    "te_df = pd.concat([te_df, Dependents__], axis = 1)\n",
    "\n",
    "# checking the our manipulated dataset for validation\n",
    "print(f\"training set (row, col): {tr_df.shape}\\n\\ntesting set (row, col): {te_df.shape}\\n\")\n",
    "print(tr_df.info(), \"\\n\\n\", te_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdab57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the correlation matrix\n",
    "sns.heatmap(tr_df.corr() ,cmap='cubehelix_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation table\n",
    "corr = tr_df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c010a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tr_df['Loan_Status']\n",
    "X = tr_df.drop('Loan_Status', axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d740d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(X_train, y_train)\n",
    "\n",
    "y_predict = DT.predict(X_test)\n",
    "\n",
    "#  prediction Summary by species\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "# Accuracy score\n",
    "DT_SC = accuracy_score(y_predict,y_test)\n",
    "print(f\"{round(DT_SC*100,2)}% Accurate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90abb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decision_Tree=pd.DataFrame({'y_test':y_test,'prediction':y_predict})\n",
    "Decision_Tree.to_csv(\"Data/Dection Tree.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f21389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "y_predict = LR.predict(X_test)\n",
    "\n",
    "#  prediction Summary by species\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "# Accuracy score\n",
    "LR_SC = accuracy_score(y_predict,y_test)\n",
    "print('accuracy is',f\"{round(accuracy_score(y_predict,y_test)*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9d221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_Regression=pd.DataFrame({'y_test':y_test,'prediction':y_predict})\n",
    "Logistic_Regression.to_csv(\"Data/Logistic Regression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91411cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "y_predict = RF.predict(X_test)\n",
    "\n",
    "#  prediction Summary by species\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "# Accuracy score\n",
    "RF_SC = accuracy_score(y_predict,y_test)\n",
    "print(f\"{round(RF_SC*100,2)}% Accurate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f134dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random_Forest=pd.DataFrame({'y_test':y_test,'prediction':y_predict})\n",
    "Random_Forest.to_csv(\"Data/Random Forest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = [DT_SC,RF_SC,LR_SC]\n",
    "Models = pd.DataFrame({\n",
    "    'n_neighbors': [\"Decision Tree\",\"Random Forest\", \"Logistic Regression\"],\n",
    "    'Score': score})\n",
    "Models.sort_values(by='Score', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
